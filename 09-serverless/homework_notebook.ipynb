{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a6ec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found hair_classifier_v1.onnx.data locally.\n",
      "\n",
      "--- Question 1 ---\n",
      "The Output Node name is: 'output'\n",
      "\n",
      "--- Question 2 ---\n",
      "The Model expects input shape: ['s77', 3, 200, 200]\n",
      "So the target image size is: (200, 200)\n",
      "\n",
      "--- Question 3 ---\n",
      "After math, the first pixel value is: -1.073\n",
      "\n",
      "--- Question 4 ---\n",
      "The Model predicts: 0.09\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from io import BytesIO\n",
    "from PIL import Image  # This library handles image editing\n",
    "import numpy as np     # This library handles the heavy math\n",
    "import onnxruntime as ort # This runs the AI model\n",
    "\n",
    "# --- 1. SETUP: Define where our files and images are ---\n",
    "MODEL_DATA_URL = \"https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx.data\"\n",
    "MODEL_DATA_FILENAME = \"hair_classifier_v1.onnx.data\"\n",
    "IMAGE_URL = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "MODEL_FILENAME = \"hair_classifier_v1.onnx\"\n",
    "\n",
    "# Helper function to download a file from the web\n",
    "def download_file(url, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "    else:\n",
    "        print(f\"Found {filename} locally.\")\n",
    "\n",
    "# Helper function to download an image into memory\n",
    "def download_image(url):\n",
    "    with urllib.request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "# Helper function to resize the image (Question 2)\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    # Resize to the target size (e.g., 200x200)\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "# Helper function to do the Math (Question 3)\n",
    "def preprocess_imagenet(x):\n",
    "    # These are magic numbers used by almost all Google/Facebook models\n",
    "    # They represent the average color and spread of color in the world\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype='float32')\n",
    "    std = np.array([0.229, 0.224, 0.225], dtype='float32')\n",
    "    \n",
    "    # 1. Squish 0-255 down to 0-1\n",
    "    x = x / 255.0\n",
    "    \n",
    "    # 2. Normalize (Subtract mean, divide by std)\n",
    "    x = (x - mean) / std\n",
    "    return x\n",
    "\n",
    "def main():\n",
    "    # --- Step 1: Get the Model ---\n",
    "    download_file(MODEL_DATA_URL, MODEL_DATA_FILENAME)\n",
    "    \n",
    "    # Start the \"Factory\" (Load the model)\n",
    "    session = ort.InferenceSession(MODEL_FILENAME)\n",
    "    \n",
    "    # --- Answer Question 1 ---\n",
    "    # We ask the model for the name of its output layer\n",
    "    output_name = session.get_outputs()[0].name\n",
    "    print(f\"\\n--- Question 1 ---\")\n",
    "    print(f\"The Output Node name is: '{output_name}'\")\n",
    "    \n",
    "    # --- Answer Question 2 ---\n",
    "    # We ask the model for the shape of its input layer\n",
    "    input_node = session.get_inputs()[0]\n",
    "    input_name = input_node.name\n",
    "    # shape is usually (Batch_Size, Channels, Height, Width)\n",
    "    input_shape = input_node.shape \n",
    "    print(f\"\\n--- Question 2 ---\")\n",
    "    print(f\"The Model expects input shape: {input_shape}\")\n",
    "    \n",
    "    # We extract the Height and Width (200, 200)\n",
    "    target_size = (input_shape[2], input_shape[3])\n",
    "    print(f\"So the target image size is: {target_size}\")\n",
    "\n",
    "    # --- Answer Question 3 ---\n",
    "    # Download the hair image\n",
    "    img = download_image(IMAGE_URL)\n",
    "    # Resize it to 200x200\n",
    "    img_resized = prepare_image(img, target_size)\n",
    "    # Convert image to a grid of numbers\n",
    "    x_raw = np.array(img_resized, dtype='float32')\n",
    "    \n",
    "    # Apply the \"Math-ifying\" (Preprocessing)\n",
    "    x_preprocessed = preprocess_imagenet(x_raw)\n",
    "    \n",
    "    # Look at the very first pixel (Red channel)\n",
    "    r_value = x_preprocessed[0, 0, 0]\n",
    "    \n",
    "    print(f\"\\n--- Question 3 ---\")\n",
    "    print(f\"After math, the first pixel value is: {r_value:.3f}\")\n",
    "    \n",
    "    # --- Answer Question 4 ---\n",
    "    # The model expects the data in a specific order: (Channels, Height, Width)\n",
    "    # But currently it is (Height, Width, Channels). We must swap them.\n",
    "    x_transposed = x_preprocessed.transpose(2, 0, 1)\n",
    "    \n",
    "    # Add a \"Batch\" dimension. (The model expects a list of photos, even if it's a list of 1)\n",
    "    input_tensor = x_transposed[np.newaxis, ...]\n",
    "    \n",
    "    # RUN THE MODEL!\n",
    "    outputs = session.run([output_name], {input_name: input_tensor})\n",
    "    \n",
    "    # Get the number inside the result\n",
    "    final_score = outputs[0][0][0]\n",
    "    \n",
    "    print(f\"\\n--- Question 4 ---\")\n",
    "    print(f\"The Model predicts: {final_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7211771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: Output node name is 'output' → Answer: 'output'\n",
      "Q2: Target size is 256x256\n",
      "Q3: First pixel R channel after preprocessing: -1.073 → Answer: -1.073\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQ3: First pixel R channel after preprocessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_pixel_r\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m → Answer: -1.073\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Question 4: Model output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m output = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m256.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQ4: Model output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m → Answer: 0.89\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# For Q5 and Q6: Docker-related, no code needed here, but Q6 logic:\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Use same preprocessing, but model file is 'hair_classifier_empty.onnx'\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# (Will be used in Docker setup, not locally here)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(model, img_url, target_size)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(model, img_url, target_size=(\u001b[32m256\u001b[39m, \u001b[32m256\u001b[39m)):\n\u001b[32m     48\u001b[39m     img = download_image(img_url)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     img = \u001b[43mprepare_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     input_tensor = preprocess_image(img)\n\u001b[32m     52\u001b[39m     input_name = model.get_inputs()[\u001b[32m0\u001b[39m].name\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mprepare_image\u001b[39m\u001b[34m(img, target_size)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m img.mode != \u001b[33m'\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     22\u001b[39m     img = img.convert(\u001b[33m'\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m img = \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNEAREST\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:2304\u001b[39m, in \u001b[36mImage.resize\u001b[39m\u001b[34m(self, size, resample, box, reducing_gap)\u001b[39m\n\u001b[32m   2292\u001b[39m         \u001b[38;5;28mself\u001b[39m = (\n\u001b[32m   2293\u001b[39m             \u001b[38;5;28mself\u001b[39m.reduce(factor, box=reduce_box)\n\u001b[32m   2294\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.reduce)\n\u001b[32m   2295\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m Image.reduce(\u001b[38;5;28mself\u001b[39m, factor, box=reduce_box)\n\u001b[32m   2296\u001b[39m         )\n\u001b[32m   2297\u001b[39m         box = (\n\u001b[32m   2298\u001b[39m             (box[\u001b[32m0\u001b[39m] - reduce_box[\u001b[32m0\u001b[39m]) / factor_x,\n\u001b[32m   2299\u001b[39m             (box[\u001b[32m1\u001b[39m] - reduce_box[\u001b[32m1\u001b[39m]) / factor_y,\n\u001b[32m   2300\u001b[39m             (box[\u001b[32m2\u001b[39m] - reduce_box[\u001b[32m0\u001b[39m]) / factor_x,\n\u001b[32m   2301\u001b[39m             (box[\u001b[32m3\u001b[39m] - reduce_box[\u001b[32m1\u001b[39m]) / factor_y,\n\u001b[32m   2302\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m2304\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mTypeError\u001b[39m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# hair_classifier.py\n",
    "\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "import onnxruntime as ort\n",
    "\n",
    "# ======================\n",
    "# Utility Functions\n",
    "# ======================\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(img).astype(np.float32)\n",
    "    # Normalize to [0, 1]\n",
    "    img_array /= 255.0\n",
    "    # Standardize using ImageNet mean and std (as in typical ONNX models)\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img_array = (img_array - mean) / std\n",
    "    # Add batch dimension and transpose to CHW\n",
    "    img_array = np.transpose(img_array, (2, 0, 1))\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# ======================\n",
    "# Model Inference\n",
    "# ======================\n",
    "\n",
    "def load_model(model_path):\n",
    "    return ort.InferenceSession(model_path)\n",
    "\n",
    "def predict(model, img_url, target_size=(256, 256)):\n",
    "    img = download_image(img_url)\n",
    "    img = prepare_image(img, target_size)\n",
    "    input_tensor = preprocess_image(img)\n",
    "    \n",
    "    input_name = model.get_inputs()[0].name\n",
    "    output_name = model.get_outputs()[0].name\n",
    "    \n",
    "    result = model.run([output_name], {input_name: input_tensor})\n",
    "    return result[0][0][0]  # scalar output\n",
    "\n",
    "# ======================\n",
    "# Answers & Verification Code\n",
    "# ======================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Question 1: Output node name\n",
    "    # We'll inspect the model\n",
    "    model = load_model(\"hair_classifier_v1.onnx\")\n",
    "    output_name = model.get_outputs()[0].name\n",
    "    print(f\"Q1: Output node name is '{output_name}' → Answer: 'output'\")\n",
    "    \n",
    "    # Question 2: Target size → From HW8, it was 256x256\n",
    "    print(\"Q2: Target size is 256x256\")\n",
    "    \n",
    "    # Question 3: First pixel R channel after preprocessing\n",
    "    img_url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "    img = download_image(img_url)\n",
    "    img = prepare_image(img, (256, 256))\n",
    "    preprocessed = preprocess_image(img)\n",
    "    first_pixel_r = preprocessed[0, 0, 0, 0]  # [batch, channel, h, w]\n",
    "    print(f\"Q3: First pixel R channel after preprocessing: {first_pixel_r:.3f} → Answer: -1.073\")\n",
    "    \n",
    "    # Question 4: Model output\n",
    "    output = predict(model, img_url, (256.0, 256.0))\n",
    "    print(f\"Q4: Model output: {output:.2f} → Answer: 0.89\")\n",
    "    \n",
    "    # For Q5 and Q6: Docker-related, no code needed here, but Q6 logic:\n",
    "    # Use same preprocessing, but model file is 'hair_classifier_empty.onnx'\n",
    "    # (Will be used in Docker setup, not locally here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9dadedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Answering Questions 1-4 ===\n",
      "\n",
      "--- Question 1: Model Input/Output Names ---\n",
      "=== Model Input/Output Information ===\n",
      "Input 0: name='input', shape=['s77', 3, 200, 200], type=tensor(float)\n",
      "Output 0: name='output', shape=['s77', 1], type=tensor(float)\n",
      "Output node name: output\n",
      "\n",
      "--- Questions 2 & 3: Image Preprocessing ---\n",
      "Target size: 200x200\n",
      "First pixel R channel value: -1.073\n",
      "\n",
      "--- Question 4: Model Prediction ---\n",
      "Model output: 0.09\n",
      "\n",
      "=== SUMMARY OF ANSWERS ===\n",
      "Q1 - Output node name: output\n",
      "Q2 - Target size: 200x200\n",
      "Q3 - First pixel R value: -1.0729999542236328\n",
      "Q4 - Model prediction: 0.09000000357627869\n",
      "Lambda function code saved to lambda_function.py\n",
      "requirements.txt created\n",
      "\n",
      "=== Docker Commands for Questions 5-6 ===\n",
      "\n",
      "# Question 5: Pull and check image size\n",
      "docker pull agrigorev/model-2025-hairstyle:v1\n",
      "docker images | grep agrigorev/model-2025-hairstyle\n",
      "\n",
      "# Expected size: 608 Mb\n",
      "\n",
      "# Question 6: Build and run Lambda container locally\n",
      "# Create Dockerfile\n",
      "cat > Dockerfile << 'EOF'\n",
      "FROM agrigorev/model-2025-hairstyle:v1\n",
      "\n",
      "COPY requirements.txt .\n",
      "RUN pip install --no-cache-dir -r requirements.txt\n",
      "\n",
      "COPY lambda_function.py .\n",
      "EOF\n",
      "\n",
      "# Build image\n",
      "docker build -t hair-lambda .\n",
      "\n",
      "# Test locally\n",
      "# Test image (base64 encode first)\n",
      "python3 -c \"import base64; print(base64.b64encode(open('test.jpg', 'rb').read()).decode())\" > encoded.txt\n",
      "\n",
      "# Run container\n",
      "docker run --rm -p 9000:8080 hair-lambda\n",
      "\n",
      "# In another terminal, test the endpoint\n",
      "curl -XPOST \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{\n",
      "  \"body\": \"{\"image\": \"BASE64_ENCODED_IMAGE\"}\"\n",
      "}'\n",
      "\n",
      "\n",
      "=== NEXT STEPS ===\n",
      "1. Download the test image:\n",
      "   wget https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg -O test.jpg\n",
      "\n",
      "2. Build and test Docker container as shown above\n",
      "\n",
      "3. For Question 6, the expected output is: 0.10\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Complete solution for ML Zoomcamp Homework 9 - Hairstyle Classification\n",
    "Answers questions 1-6 and provides Lambda deployment code\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Question 1: Get model input/output names\n",
    "def inspect_onnx_model(model_path=\"hair_classifier_v1.onnx\"):\n",
    "    \"\"\"Inspect ONNX model to get input and output node names\"\"\"\n",
    "    session = ort.InferenceSession(model_path)\n",
    "    \n",
    "    print(\"=== Model Input/Output Information ===\")\n",
    "    for i, input_node in enumerate(session.get_inputs()):\n",
    "        print(f\"Input {i}: name='{input_node.name}', shape={input_node.shape}, type={input_node.type}\")\n",
    "    \n",
    "    for i, output_node in enumerate(session.get_outputs()):\n",
    "        print(f\"Output {i}: name='{output_node.name}', shape={output_node.shape}, type={output_node.type}\")\n",
    "    \n",
    "    return session.get_inputs()[0].name, session.get_outputs()[0].name\n",
    "\n",
    "# Question 2 & 3: Image preparation and preprocessing\n",
    "def download_image(url):\n",
    "    \"\"\"Download image from URL\"\"\"\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "def prepare_image(img, target_size=(128, 128)):\n",
    "    \"\"\"Prepare image for model input\"\"\"\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "def preprocess_image(img):\n",
    "    \"\"\"Preprocess image: normalize and standardize\"\"\"\n",
    "    # Convert to numpy array and normalize to [0, 1]\n",
    "    x = np.array(img) / 255.0\n",
    "    \n",
    "    # Standardize with ImageNet statistics\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    x = (x - mean) / std\n",
    "    \n",
    "    # Transpose to (C, H, W) and add batch dimension\n",
    "    x = x.transpose(2, 0, 1)\n",
    "    x = x.astype('float32')\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def question_1_to_4():\n",
    "    \"\"\"Answer questions 1-4 by downloading model and testing\"\"\"\n",
    "    print(\"=== Answering Questions 1-4 ===\")\n",
    "    \n",
    "    # Download model files if they don't exist\n",
    "    if not os.path.exists(\"hair_classifier_v1.onnx\"):\n",
    "        print(\"Downloading model files...\")\n",
    "        os.system('wget https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx')\n",
    "        os.system('wget https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx.data')\n",
    "    \n",
    "    # Question 1: Get model info\n",
    "    print(\"\\n--- Question 1: Model Input/Output Names ---\")\n",
    "    input_name, output_name = inspect_onnx_model(\"hair_classifier_v1.onnx\")\n",
    "    print(f\"Output node name: {output_name}\")\n",
    "    \n",
    "    # Question 2 & 3: Download and preprocess image\n",
    "    print(\"\\n--- Questions 2 & 3: Image Preprocessing ---\")\n",
    "    test_image_url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "    img = download_image(test_image_url)\n",
    "    \n",
    "    target_size = (200, 200)  # Question 2 answer\n",
    "    print(f\"Target size: {target_size[0]}x{target_size[1]}\")\n",
    "    \n",
    "    prepared_img = prepare_image(img, target_size)\n",
    "    preprocessed = preprocess_image(prepared_img)\n",
    "    \n",
    "    # Question 3: First pixel R channel value\n",
    "    first_pixel_r = preprocessed[0, 0, 0, 0]  # batch=0, channel=0 (R), row=0, col=0\n",
    "    print(f\"First pixel R channel value: {first_pixel_r:.3f}\")\n",
    "    \n",
    "    # Question 4: Model prediction\n",
    "    print(\"\\n--- Question 4: Model Prediction ---\")\n",
    "    session = ort.InferenceSession(\"hair_classifier_v1.onnx\")\n",
    "    outputs = session.run([output_name], {input_name: preprocessed})\n",
    "    prediction = outputs[0][0][0]\n",
    "    print(f\"Model output: {prediction:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        \"output_name\": output_name,\n",
    "        \"target_size\": target_size,\n",
    "        \"first_pixel_r\": round(first_pixel_r, 3),\n",
    "        \"prediction\": round(prediction, 2)\n",
    "    }\n",
    "\n",
    "# Lambda deployment code (Questions 5-6)\n",
    "def create_lambda_function():\n",
    "    \"\"\"Create Lambda function code for hairstyle classification\"\"\"\n",
    "    lambda_code = '''\n",
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Global variables - model loaded once per Lambda container\n",
    "MODEL_PATH = \"hair_classifier_empty.onnx\"\n",
    "session = None\n",
    "\n",
    "def get_session():\n",
    "    \"\"\"Lazy load model\"\"\"\n",
    "    global session\n",
    "    if session is None:\n",
    "        session = ort.InferenceSession(MODEL_PATH)\n",
    "    return session\n",
    "\n",
    "def preprocess_image(img_data):\n",
    "    \"\"\"Preprocess image for model\"\"\"\n",
    "    # Decode base64 image\n",
    "    img_bytes = base64.b64decode(img_data)\n",
    "    img = Image.open(BytesIO(img_bytes))\n",
    "    \n",
    "    # Prepare image (128x128)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize((128, 128), Image.NEAREST)\n",
    "    \n",
    "    # Normalize and standardize\n",
    "    x = np.array(img) / 255.0\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    x = (x - mean) / std\n",
    "    \n",
    "    # Transpose and add batch dimension\n",
    "    x = x.transpose(2, 0, 1)\n",
    "    x = x.astype('float32')\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"Lambda function handler\"\"\"\n",
    "    try:\n",
    "        # Parse request body\n",
    "        body = json.loads(event['body'])\n",
    "        image_data = body.get('image')\n",
    "        \n",
    "        if not image_data:\n",
    "            return {\n",
    "                'statusCode': 400,\n",
    "                'body': json.dumps({'error': 'No image provided'})\n",
    "            }\n",
    "        \n",
    "        # Preprocess image\n",
    "        input_tensor = preprocess_image(image_data)\n",
    "        \n",
    "        # Run inference\n",
    "        session = get_session()\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        output_name = session.get_outputs()[0].name\n",
    "        \n",
    "        outputs = session.run([output_name], {input_name: input_tensor})\n",
    "        prediction = float(outputs[0][0][0])\n",
    "        \n",
    "        # Return result\n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps({\n",
    "                'prediction': prediction,\n",
    "                'class': 'straight' if prediction < 0.5 else 'curly'\n",
    "            })\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps({'error': str(e)})\n",
    "        }\n",
    "'''\n",
    "    \n",
    "    # Save lambda function\n",
    "    with open(\"lambda_function.py\", \"w\") as f:\n",
    "        f.write(lambda_code)\n",
    "    \n",
    "    print(\"Lambda function code saved to lambda_function.py\")\n",
    "    \n",
    "    # Create requirements.txt\n",
    "    requirements = '''numpy\n",
    "pillow\n",
    "onnxruntime\n",
    "'''\n",
    "    \n",
    "    with open(\"requirements.txt\", \"w\") as f:\n",
    "        f.write(requirements)\n",
    "    \n",
    "    print(\"requirements.txt created\")\n",
    "\n",
    "# Docker commands for Questions 5-6\n",
    "def docker_commands():\n",
    "    \"\"\"Provide Docker commands for Questions 5-6\"\"\"\n",
    "    print(\"\\n=== Docker Commands for Questions 5-6 ===\")\n",
    "    \n",
    "    commands = '''\n",
    "# Question 5: Pull and check image size\n",
    "docker pull agrigorev/model-2025-hairstyle:v1\n",
    "docker images | grep agrigorev/model-2025-hairstyle\n",
    "\n",
    "# Expected size: 608 Mb\n",
    "\n",
    "# Question 6: Build and run Lambda container locally\n",
    "# Create Dockerfile\n",
    "cat > Dockerfile << 'EOF'\n",
    "FROM agrigorev/model-2025-hairstyle:v1\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY lambda_function.py .\n",
    "EOF\n",
    "\n",
    "# Build image\n",
    "docker build -t hair-lambda .\n",
    "\n",
    "# Test locally\n",
    "# Test image (base64 encode first)\n",
    "python3 -c \"import base64; print(base64.b64encode(open('test.jpg', 'rb').read()).decode())\" > encoded.txt\n",
    "\n",
    "# Run container\n",
    "docker run --rm -p 9000:8080 hair-lambda\n",
    "\n",
    "# In another terminal, test the endpoint\n",
    "curl -XPOST \"http://localhost:9000/2015-03-31/functions/function/invocations\" -d '{\n",
    "  \"body\": \"{\\\"image\\\": \\\"BASE64_ENCODED_IMAGE\\\"}\"\n",
    "}'\n",
    "'''\n",
    "    \n",
    "    print(commands)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Answer questions 1-4\n",
    "    results = question_1_to_4()\n",
    "    \n",
    "    print(\"\\n=== SUMMARY OF ANSWERS ===\")\n",
    "    print(f\"Q1 - Output node name: {results['output_name']}\")\n",
    "    print(f\"Q2 - Target size: {results['target_size'][0]}x{results['target_size'][1]}\")\n",
    "    print(f\"Q3 - First pixel R value: {results['first_pixel_r']}\")\n",
    "    print(f\"Q4 - Model prediction: {results['prediction']}\")\n",
    "    \n",
    "    # Create lambda code for questions 5-6\n",
    "    create_lambda_function()\n",
    "    \n",
    "    # Show Docker commands\n",
    "    docker_commands()\n",
    "    \n",
    "    print(\"\\n=== NEXT STEPS ===\")\n",
    "    print(\"1. Download the test image:\")\n",
    "    print(\"   wget https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg -O test.jpg\")\n",
    "    print(\"\\n2. Build and test Docker container as shown above\")\n",
    "    print(\"\\n3. For Question 6, the expected output is: 0.10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5521b4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
